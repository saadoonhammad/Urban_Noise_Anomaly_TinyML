{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "teGdwyWu8KHK"
      },
      "outputs": [],
      "source": [
        "!pip show tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfyAxMH3ZA3c"
      },
      "outputs": [],
      "source": [
        "pip install -U kaleido"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNl_8TiPrhIS"
      },
      "outputs": [],
      "source": [
        "# Define paths to model files\n",
        "import os\n",
        "MODELS_DIR = 'models/'\n",
        "if not os.path.exists(MODELS_DIR):\n",
        "    os.mkdir(MODELS_DIR)\n",
        "MODEL_TF = MODELS_DIR + 'model'\n",
        "MODEL_KERAS= MODELS_DIR + 'keras.h5'\n",
        "MODEL_NO_QUANT_TFLITE = MODELS_DIR + 'model_no_quant.tflite'\n",
        "# MODEL_DYN_TFLITE = MODELS_DIR + 'model_dyn_quant.tflite'\n",
        "MODEL_TFLITE = MODELS_DIR + 'model.tflite'\n",
        "MODEL_TFLITE_MICRO = MODELS_DIR + 'model.cc'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5k1b94zdN-q"
      },
      "outputs": [],
      "source": [
        "#Importing Libaries\n",
        "import os\n",
        "import random\n",
        "from os import listdir\n",
        "from io import StringIO\n",
        "from os.path import join\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import plotly.express as px\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from scipy.stats import median_abs_deviation\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, QuantileTransformer, RobustScaler, MaxAbsScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, RepeatVector, TimeDistributed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bz8hC4WzdX57"
      },
      "outputs": [],
      "source": [
        "#IMPORTING DATA\n",
        "helsinki=pd.read_csv('path/LAeq-2019-all.csv')\n",
        "helsinki.time= pd.to_datetime(helsinki['time'], unit='ms').astype('datetime64')\n",
        "helsinki['date']=helsinki['time'].dt.date.astype('datetime64')\n",
        "helsinki['hour']=helsinki['time'].dt.hour\n",
        "helsinki['dow']= helsinki['time'].dt.day_name()\n",
        "helsinki['month']=helsinki['time'].dt.month\n",
        "helsinki['day']=helsinki['time'].dt.day\n",
        "helsinki['nod']=pd.Categorical(helsinki['dow'], categories=\n",
        "    ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday', 'Sunday'],\n",
        "    ordered=True)\n",
        "df_helsinki= helsinki [['time', 'dBA', 'dev-id', 'date', 'hour', 'dow', 'month', 'day', 'nod']]\n",
        "df_helsinki.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2mdGr0-dX9N"
      },
      "outputs": [],
      "source": [
        " #DICTIONARY FOR KEY-VALUE PAIRS IDENTIFYING EACH SENSOR ID WITH A UNIQUE NUMBER\n",
        " sensors = {\"TA120-T246177\" : 2, \"TA120-T246182\" : 3,\"TA120-T246183\" : 4,\"TA120-T246184\" : 5,\n",
        "            \"TA120-T246187\" : 6,\"TA120-T246189\" : 7,\"TA120-T246191\" : 8}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6UvmQ6LdYAG"
      },
      "outputs": [],
      "source": [
        "#MAPPING THE KEYS 'dev-id' IN DATAFRAME WITH VALUES \n",
        "df_helsinki['sensor'] = df_helsinki['dev-id'].map(sensors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBeJL9JmeYCy",
        "outputId": "3dccd20a-33b0-4b6b-8f3f-c0b47fb588f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "time      520118\n",
              "dBA       520118\n",
              "dev-id    520118\n",
              "date      520118\n",
              "hour      520118\n",
              "dow       520118\n",
              "month     520118\n",
              "day       520118\n",
              "nod       520118\n",
              "sensor    520118\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "#SELECTING THE SENSOR WITH ID TA120-T246187\n",
        "df_187= df_helsinki.loc[(df_helsinki ['sensor'] == 6)  ]\n",
        "df_187.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pi5QUueDEKjt"
      },
      "outputs": [],
      "source": [
        "fig= px.line(df_187, x='time', y='dBA',  title='Scatterplot of sound values')\n",
        "fig.update_xaxes(rangeslider_visible=True)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dF1STyP5aTf_",
        "outputId": "f3f02fdc-c67c-4685-977e-d45858de3d67"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(518678, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "#REMOVING VALUES BEFORE 2019\n",
        "df_187= df_187[df_187['date'] > '2018-12-31']\n",
        "df_187.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJtoxXyCZjvn"
      },
      "outputs": [],
      "source": [
        "#DUPLICATES REMOVAL BASED ON TIME COLUMN. \n",
        "df_187 = df_187.drop_duplicates(subset = [\"time\"], keep='first')\n",
        "df_187.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1fq_JWhgVNp"
      },
      "outputs": [],
      "source": [
        "df_187.groupby('date').filter(lambda g: len(g) < 1439).groupby('date').size().sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnZSpmrqi0sT"
      },
      "outputs": [],
      "source": [
        "#rds\n",
        "df_187_new= pd.DataFrame(df_187.groupby('date').filter(lambda g: len(g) < 1439).groupby('date').size().sort_values(ascending=False))\n",
        "df_187_new.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNEKVIYSWfM2"
      },
      "outputs": [],
      "source": [
        "df_187= df_187.drop(df_187.loc[df_187['date'].isin(df_187_new.index)].index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZN0XaqTVZSkU"
      },
      "outputs": [],
      "source": [
        "#CHECK FOR NULL VALUES\n",
        "df_187.isnull().values.any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtKYwBVDHypW"
      },
      "outputs": [],
      "source": [
        "#SORT VALUES BY TIME\n",
        "df_187=df_187.sort_values('time')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JWfr7dAdYyq"
      },
      "outputs": [],
      "source": [
        "#DATASTATS AFTER CLEANING OF DATA\n",
        "df_187.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8Cia3ptebYQ"
      },
      "outputs": [],
      "source": [
        "fig= px.line(df_187, x='time', y='dBA',  title='Lineplot of sound values')\n",
        "fig.update_xaxes(rangeslider_visible=True)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlKpC4aFebKq"
      },
      "outputs": [],
      "source": [
        "df_187_hourly=df_187.groupby(['hour'])['hour'].count()\n",
        "fig= px.bar(df_187_hourly, text='value', labels={ 'index': 'hour', 'value':'count'}, title='Total count per hour', width=1000,height=600)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRjmG-FzekCQ"
      },
      "outputs": [],
      "source": [
        "df_187_hourly_mean=df_187[['dBA', 'hour']].groupby(['hour']).mean()\n",
        "fig= px.line(df_187_hourly_mean,text=df_187_hourly_mean.index, title='Sound values aggregated by hour',\n",
        "             labels={'value':'Noise Value (dBA)', 'hour': 'Hour'}, width=1000,height=600)\n",
        "fig.update_traces(textposition='top right')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdJyXAFaqu5i"
      },
      "outputs": [],
      "source": [
        "daily_count=pd.DataFrame((df_187.groupby(['date'])['dBA'].count()))\n",
        "daily_count\n",
        "daily_count.loc[(daily_count['dBA']< 1440) & (daily_count.index > '2019-01-01')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfp19hM1ej5B"
      },
      "outputs": [],
      "source": [
        "df_187_daily=df_187.groupby(['date'])['date'].count()\n",
        "fig= px.bar(df_187_daily, text='value', labels={ 'index': 'Day', 'value':'count'}, title='Total count per day', width=1500,height=600)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JD1Hs3vyetJP"
      },
      "outputs": [],
      "source": [
        "df_187_daily_mean=df_187[['dBA', 'date']].groupby(['date']).mean()\n",
        "fig= px.line(df_187_daily_mean, title='Sound values aggregated by day',\n",
        "             labels={'value':'Noise Value (dBA)', 'date': 'Date'}, width=1500,height=600)\n",
        "# fig.update_traces(textposition='top right')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYDs5LjCes8Z"
      },
      "outputs": [],
      "source": [
        "df_187_nod=df_187.groupby(['nod'])['nod'].count()\n",
        "fig= px.bar(df_187_nod, text='value', labels={ 'index': 'hour', 'value':'count'}, title='Total count per day of week', width=1400,height=600)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sA5-MZqses3v"
      },
      "outputs": [],
      "source": [
        "df_187_nod_mean=df_187[['dBA', 'nod']].groupby(['nod']).mean()\n",
        "fig= px.line(df_187_nod_mean, text=df_187_nod_mean.index, title='Sound values aggregated by day of week', width=1500,height=600)\n",
        "fig.update_traces(textposition='top right')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJblXDCHdAol"
      },
      "outputs": [],
      "source": [
        "df_187_monthly_count=df_187[['dBA', 'month']].groupby(['month']).count()\n",
        "fig= px.bar(df_187_monthly_count, text='value', labels={ 'index': 'month', 'value':'count'}, title='Total count by month of year', width=1400,height=600)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ki-s7Hs9vvXy"
      },
      "outputs": [],
      "source": [
        "df_187_march= df_187.loc[df_187['month'] == 3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9w-UJHmvvJE"
      },
      "outputs": [],
      "source": [
        "fig= px.line(df_187_march, x='time', y='dBA',  title='Lineplot of of noise level', width=1400,height=600, labels={'dBA':'Noise Value (dBA)', 'time': 'Date'})\n",
        "# fig.update_xaxes(rangeslider_visible=True)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKQNL4e6fYOe"
      },
      "outputs": [],
      "source": [
        "df_187.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wswhcd-f_aXE"
      },
      "source": [
        "**Data preparation for LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_oWJ13r81Ad"
      },
      "outputs": [],
      "source": [
        "df_187['month'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btCuwy6pygbb"
      },
      "outputs": [],
      "source": [
        "# test = df_187.loc[(df_187['month'].isin ([3,9,10])) | df_187['date'].isin (['2019-11-11', '2019-11-30', '2019-12-10', '2019-12-14']) ]\n",
        "test = df_187.loc[(df_187['month'].isin ([8,  9, 10])) ]\n",
        "test.to_csv('/content/test.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FQVXnQT6A0t"
      },
      "outputs": [],
      "source": [
        "# train= df_187.loc[~df_187.index.isin (test.index)]\n",
        "train= df_187.loc[(df_187['month'].isin ([ 1,  2,  3,  4,  5,  6,  7, 11, 12]))]\n",
        "train.to_csv('/content/train.csv', index=False)\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3tV_fz6DoZD"
      },
      "outputs": [],
      "source": [
        "train=pd.read_csv('/content/train.csv')\n",
        "test=pd.read_csv('/content/test.csv')\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nA-IdixT56P-"
      },
      "outputs": [],
      "source": [
        "train=train.sort_values('time')\n",
        "fig= px.line(train, x='time', y='dBA',  title='Lineplot of sound values')\n",
        "fig.update_xaxes(rangeslider_visible=True)\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8n-Vbdy51Dr"
      },
      "outputs": [],
      "source": [
        "test=test.sort_values('time')\n",
        "fig= px.line(test, x='time', y='dBA',  title='Lineplot of sound values')\n",
        "fig.update_xaxes(rangeslider_visible=True)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzAw3PbDbp8Y"
      },
      "outputs": [],
      "source": [
        "test.loc[test['dBA'] > 90, 'Class'] = 'Anomaly'\n",
        "test.loc[test['dBA'] < 90, 'Class'] = 'Normal'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRgXU9c5VA4L"
      },
      "outputs": [],
      "source": [
        "#Fitting the scaler\n",
        "scaler= MinMaxScaler()\n",
        "# scaler= MaxAbsScaler()\n",
        "scaler = scaler.fit(train[['dBA']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRwUHrjLuTpp"
      },
      "outputs": [],
      "source": [
        "train['dBA'] = scaler.transform(train[['dBA']])\n",
        "test['dBA'] = scaler.transform(test[['dBA']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGrYe4VFWqjJ",
        "outputId": "6d801222-23cb-430a-e3a3-5a0945e6636d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0020876826722336927, 0.0, 1.1941544885177457, 1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "test['dBA'].min(), train['dBA'].min() , test['dBA'].max(), train['dBA'].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6Tj4MMWVhpS"
      },
      "outputs": [],
      "source": [
        "seq_size = 1\n",
        "def to_sequences(x, y, seq_size=1):\n",
        "    x_values = []\n",
        "    y_values = []\n",
        "\n",
        "    for i in range(len(x)-seq_size):\n",
        "        #print(i)\n",
        "        x_values.append(x.iloc[i:(i+seq_size)].values)\n",
        "        y_values.append(y.iloc[i+seq_size])\n",
        "        \n",
        "    return np.array(x_values), np.array(y_values)\n",
        "\n",
        "trainX, trainY = to_sequences(train[['dBA']], train['dBA'], seq_size)\n",
        "testX, testY = to_sequences(test[['dBA']], test['dBA'], seq_size)\n",
        "# testxX, testxY = to_sequences(testx[['dBA']], testx['dBA'], seq_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTHNiqb1RT8p",
        "outputId": "9cfd1779-9057-4be2-f6b6-b965567c70c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[0.48016701]]), dtype('float64'), array([[0.480167]], dtype=float32))"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainX[0], trainX[0].dtype, trainX[0].astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Io_tFJVQLny4",
        "outputId": "3116c19f-516f-4f4b-cd26-86873b536232"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(dtype('float64'),\n",
              " array([[0.21503131]], dtype=float32),\n",
              " 0.20876826,\n",
              " (1, 1),\n",
              " (359985,),\n",
              " (129593, 1, 1),\n",
              " (129593,))"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainX.dtype, trainX[33712].astype(np.float32), trainY[33712].astype(np.float32), trainX[1].shape, trainY.shape, testX.shape, testY.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbhwG0ugcvBL",
        "outputId": "2d68bccd-8f45-4896-a27c-e15893fcd0a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.22546972]], dtype=float32)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainX[129590].astype(np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nugh4x7sVix9"
      },
      "source": [
        "**LSTM Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZaDd0BHg9Xh"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnMNzdGLG-wx"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(16, activation='tanh', input_shape=(trainX.shape[1], trainX.shape[2]),return_sequences=False, unroll=True))\n",
        "# model.add(LSTM(8, activation='tanh', return_sequences=False))\n",
        "# model.add(Dropout(rate=0.05))\n",
        "model.add(RepeatVector(trainX.shape[1]))\n",
        "# model.add(LSTM(8, activation='tanh', return_sequences=True))\n",
        "model.add(LSTM(16, activation='tanh', return_sequences=True, unroll=True))\n",
        "# model.add(Dropout(rate=0.05))\n",
        "model.add(TimeDistributed(Dense(trainX.shape[2])))\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001), loss=\"mae\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSWT8DZUQWn2"
      },
      "outputs": [],
      "source": [
        "history= model.fit(trainX, trainY, epochs=15, batch_size=32, validation_split=0.10 ,verbose=1, shuffle=False)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amq7KcJcIe0w"
      },
      "outputs": [],
      "source": [
        "loss= px.line(history.history, width=750, height=600, title= 'Training Loss Curve')\n",
        "loss.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2GPdTQkYC_7"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'], label='Training loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation loss')\n",
        "# plt.yticks(np.arange(0.00, 0.50, 0.01))\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iypv7E2uf1HQ",
        "outputId": "b236f46f-5bac-43b6-c1a5-a56f52c5192f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4050/4050 [==============================] - 8s 2ms/step - loss: 0.0326 - mse: 0.0022\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.032632868736982346, 0.002223391318693757]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "model.evaluate(testX, testY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqlijiD4gC14",
        "outputId": "0b07cc0b-a78c-4f5f-b510-be0d620bdbbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11250/11250 [==============================] - 18s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "trainPredict = model.predict(trainX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WemaRAIkRkeS"
      },
      "outputs": [],
      "source": [
        "trainMAE = np.mean(np.abs(trainPredict - trainX), axis=1)\n",
        "max_trainMAE = np.max(trainMAE)\n",
        "hist= px.histogram(trainMAE, nbins=30, width=750,height=500, title='Train MAE Distribution')\n",
        "hist.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OlkdhTnsbdq"
      },
      "outputs": [],
      "source": [
        "testPredict = model.predict(testX)\n",
        "print(testPredict.shape)\n",
        "print(testX.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBhFU3l5RyB3"
      },
      "outputs": [],
      "source": [
        "testMAE = np.mean(np.abs(testPredict - testX), axis=1)\n",
        "hist= px.histogram(testMAE, nbins=30, width=750,height=500, title='Test MAE Distribution')\n",
        "hist.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZSOdb_lgNTc"
      },
      "outputs": [],
      "source": [
        "anomaly_df = pd.DataFrame(test[seq_size:])\n",
        "anomaly_df['testMAE'] = testMAE\n",
        "anomaly_df['max_trainMAE'] = max_trainMAE\n",
        "anomaly_df['anomaly'] = anomaly_df['testMAE'] > anomaly_df['max_trainMAE']\n",
        "anomaly_df['dBA'] = test[seq_size:]['dBA']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lggUog31SHAV"
      },
      "outputs": [],
      "source": [
        "anomaly_df.loc[anomaly_df['anomaly'] == True]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-4K9kOIA7d-"
      },
      "outputs": [],
      "source": [
        "anomaly_df.loc[anomaly_df['anomaly'] == True].count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CRQ4SWlgO2k"
      },
      "outputs": [],
      "source": [
        "sns.lineplot(x=anomaly_df['date'], y=anomaly_df['testMAE'])\n",
        "sns.lineplot(x=anomaly_df['date'], y=anomaly_df['max_trainMAE'])\n",
        "anomalies = anomaly_df.loc[anomaly_df['anomaly'] == True]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMtZm2nNxd33"
      },
      "outputs": [],
      "source": [
        "anomalies.loc[anomalies['Class']== 'Anomaly'].count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GJk1N9zdM5E"
      },
      "outputs": [],
      "source": [
        "#INVERSE SCALER \n",
        "anomaly_df_values= scaler.inverse_transform(anomaly_df['dBA'].values.reshape(-1,1))\n",
        "anomalies_df_values=scaler.inverse_transform(anomalies['dBA'].values.reshape(-1,1))\n",
        "anomaly_df_values=pd.DataFrame(anomaly_df_values, columns=['dBA'])\n",
        "anomalies_df_values=pd.DataFrame(anomalies_df_values, columns=['dBA'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_mohuG-TKKf"
      },
      "outputs": [],
      "source": [
        "fig= px.line(x=anomaly_df['time'], y=anomaly_df['testMAE'],  title='Lineplot of sound values', labels={'x':'Time', 'y':'Scaled dBA Values'})\n",
        "fig.add_scatter(x=anomaly_df['time'], y=anomaly_df['max_trainMAE'], mode='lines')\n",
        "fig.update_xaxes(rangeslider_visible=True)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhiIkCsAcQZc"
      },
      "outputs": [],
      "source": [
        "import plotly.io as pio\n",
        "overlay_inverse=pd.DataFrame(scaler.inverse_transform(testX.reshape(-1,1)))\n",
        "overlay_inverse['predict_original']= scaler.inverse_transform(testPredict.reshape(-1,1))\n",
        "x1= overlay_inverse.index\n",
        "y3= overlay_inverse[0]\n",
        "y4= overlay_inverse['predict_original']\n",
        "fig = go.Figure()\n",
        "\n",
        "# Add traces\n",
        "fig.add_trace(go.Scatter(x=x1, y=y3,\n",
        "                    mode='markers',\n",
        "                    name='Observed'))\n",
        "fig.add_trace(go.Scatter(x=x1, y=y4,\n",
        "                    mode='markers',\n",
        "                    name='Predicted'))\n",
        "fig.update_layout(\n",
        "    plot_bgcolor='white',\n",
        "    width=1281,\n",
        "    height=785\n",
        "    \n",
        ")\n",
        "fig.update_layout(legend=dict(\n",
        "    yanchor=\"top\",\n",
        "    y=0.99,\n",
        "    xanchor=\"right\",\n",
        "    x=0.99\n",
        "))\n",
        "\n",
        "fig.update_xaxes(\n",
        "    mirror=True,\n",
        "    ticks='outside',\n",
        "    showline=True,\n",
        "    linecolor='lightgrey',\n",
        "    gridcolor='lightgrey'\n",
        ")\n",
        "fig.update_yaxes(\n",
        "    title_text=\"Noise Value (dBA)\",\n",
        "    mirror=True,\n",
        "    ticks='outside',\n",
        "    showline=True,\n",
        "    linecolor='lightgrey',\n",
        "    gridcolor='lightgrey'\n",
        ")\n",
        "# pio.write_image(fig, 'obs_pred_187.png',  scale=2)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhtY_JDRenQa"
      },
      "outputs": [],
      "source": [
        "# fig = go.Figure()\n",
        "# fig.add_trace(go.Scatter(x=anomaly_df['time'], y=b, name='Close price'))\n",
        "# fig.add_trace(go.Scatter(x=anomalies['time'], y=b2, mode='markers', name='Anomaly'))\n",
        "# fig.update_layout(showlegend=True, title='Detected anomalies')\n",
        "# fig.show()\n",
        "\n",
        "fig= px.line(x=anomaly_df['time'], y=anomaly_df['dBA'],  title='Lineplot of sound values', height=600)\n",
        "fig.add_scatter(x=anomalies['time'], y=anomalies['dBA'], mode='markers')\n",
        "# fig.add_scatter(x=anomalies['time'], y=b2, mode= 'markers')\n",
        "fig.update_xaxes(rangeslider_visible=True)\n",
        "fig.update_layout(\n",
        "    title={\n",
        "        'text': \"Lineplot of sound values\",\n",
        "        'y':0.9,\n",
        "        'x':0.5,\n",
        "        'xanchor': 'center',\n",
        "        'yanchor': 'top'})\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8OAip5JZlKj"
      },
      "outputs": [],
      "source": [
        "#VISUALIZE ORIGINAL VALUES WITH ANOMALIES\n",
        "import plotly.io as pio\n",
        "fig= px.line(x=anomaly_df['time'], y=anomaly_df_values['dBA'], labels={'x':'Date', 'y':'dBA'}, )\n",
        "fig.add_scatter(x=anomalies['time'], y=anomalies_df_values['dBA'], mode='markers', name= 'Detected Anomalies',)\n",
        "# fig.add_scatter(x=anomalies['time'], y=b2, mode= 'markers')\n",
        "# fig.update_xaxes(rangeslider_visible=True)\n",
        "fig.update_layout(\n",
        "    plot_bgcolor='white',\n",
        "    width=1281,\n",
        "    height=785\n",
        "    \n",
        ")\n",
        "fig.update_layout(legend=dict(\n",
        "    yanchor=\"top\",\n",
        "    y=0.99,\n",
        "    xanchor=\"right\",\n",
        "    x=0.99\n",
        "))\n",
        "\n",
        "fig.update_xaxes(\n",
        "    mirror=True,\n",
        "    ticks='outside',\n",
        "    showline=True,\n",
        "    linecolor='lightgrey',\n",
        "    gridcolor='lightgrey'\n",
        ")\n",
        "fig.update_yaxes(\n",
        "    title_text=\"Noise Value (dBA)\",\n",
        "    mirror=True,\n",
        "    ticks='outside',\n",
        "    showline=True,\n",
        "    linecolor='lightgrey',\n",
        "    gridcolor='lightgrey')\n",
        "# pio.write_image(fig, 'detected_anomalies_187.png',  scale=2)\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.io as pio\n",
        "overlay_inverse=pd.DataFrame(scaler.inverse_transform(testX.reshape(-1,1)))\n",
        "overlay_inverse['predict_original']= scaler.inverse_transform(testPredict.reshape(-1,1))\n",
        "x1= overlay_inverse.index\n",
        "y3= overlay_inverse[0]\n",
        "y4= overlay_inverse['predict_original']\n",
        "fig = go.Figure()\n",
        "\n",
        "# Add traces\n",
        "fig.add_trace(go.Scatter(x=anomaly_df['time'], y=anomaly_df_values['dBA'],\n",
        "                    mode='lines',\n",
        "                    name='Observed'))\n",
        "fig.add_trace(go.Scatter(x=anomalies['time'], y=anomalies_df_values['dBA'], mode='markers', name= 'Detected Anomalies',))\n",
        "\n",
        "fig.update_layout(\n",
        "    plot_bgcolor='white',\n",
        "    width=1281,\n",
        "    height=785\n",
        "    \n",
        ")\n",
        "fig.update_layout(legend=dict(\n",
        "    yanchor=\"top\",\n",
        "    y=0.99,\n",
        "    xanchor=\"right\",\n",
        "    x=0.99\n",
        "))\n",
        "\n",
        "fig.update_xaxes(\n",
        "    title_text=\"Date\",\n",
        "    mirror=True,\n",
        "    ticks='outside',\n",
        "    showline=True,\n",
        "    linecolor='lightgrey',\n",
        "    gridcolor='lightgrey'\n",
        ")\n",
        "fig.update_yaxes(\n",
        "    title_text=\"Noise Value (dBA)\",\n",
        "    mirror=True,\n",
        "    ticks='outside',\n",
        "    showline=True,\n",
        "    linecolor='lightgrey',\n",
        "    gridcolor='lightgrey'\n",
        ")\n",
        "pio.write_image(fig, 'detected_anomalies_187.png',  scale=2)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "E0jyTrp_VqrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKIM6v_XaZCV"
      },
      "source": [
        "**Evaluation Metrics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iu5FkDcUaIjW",
        "outputId": "729e5b9a-fd1d-4eb2-ebab-5a33e7d5bf4c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(34, 6, 129551, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "# true_anomaly= anomalies['Class'].loc[anomalies['Class']== 'Anomaly'].count()\n",
        "# false_anomaly= anomalies['Class'].loc[anomalies['Class']== 'Normal'].count()\n",
        "# true_normal= test['Class'].loc[test['Class']== 'Normal'].count() - false_anomaly\n",
        "# false_normal= test['Class'].loc[test['Class']== 'Anomaly'].count() - true_anomaly \n",
        "# true_anomaly, false_anomaly, true_normal, false_normal\n",
        "\n",
        "true_negatives= anomalies['Class'].loc[anomalies['Class']== 'Anomaly'].count()\n",
        "false_negatives= anomalies['Class'].loc[anomalies['Class']== 'Normal'].count()\n",
        "true_positives= test['Class'].loc[test['Class']== 'Normal'].count() - false_negatives\n",
        "false_positives= test['Class'].loc[test['Class']== 'Anomaly'].count() - true_negatives \n",
        "true_negatives, false_negatives, true_positives, false_positives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pedzYKTbAj21"
      },
      "outputs": [],
      "source": [
        " anomalies.loc[(anomalies['Class'] == 'Normal') & (anomalies['anomaly']== True)].count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WKWjqJYDhgM"
      },
      "outputs": [],
      "source": [
        " anomalies.loc[(anomalies['Class'] == 'Anomaly') & (anomalies['anomaly']== False)].count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aygTrv5AEWkl"
      },
      "outputs": [],
      "source": [
        "test.loc[test['Class'] == 'Normal'].count()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_positives= anomalies['Class'].loc[anomalies['Class']== 'Anomaly'].count()\n",
        "false_positives= anomalies['Class'].loc[anomalies['Class']== 'Normal'].count()\n",
        "true_negatives= test['Class'].loc[test['Class']== 'Normal'].count() - false_positives\n",
        "false_negatives= test['Class'].loc[test['Class']== 'Anomaly'].count() - true_positives \n",
        "true_positives, false_positives, true_negatives, false_negatives"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03OBAgBkqBjV",
        "outputId": "3861efea-fd3b-4b43-da5e-cdfe7ba7ebf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(34, 6, 129551, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "con_matrix=pd.DataFrame.from_records(\n",
        "    [[\"TensorFlow\", true_positives, false_positives],\n",
        "     [\"TensorFlow Lite\", false_negatives, true_negatives]],\n",
        "     columns = [\"Model\", \"Anomaly\", \"Normal\"], index=\"Model\")\n",
        "con_matrix"
      ],
      "metadata": {
        "id": "brjnhlbZqF7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76dtjCFAkQtg"
      },
      "outputs": [],
      "source": [
        "import plotly.io as pio\n",
        "z = [[true_positives, false_positives],\n",
        "     [false_negatives, true_negatives]]\n",
        "\n",
        "x = ['Anomaly', 'Normal']\n",
        "y = ['Anomaly', 'Normal']\n",
        "\n",
        "z_text =  [[true_positives, false_positives],\n",
        "     [false_negatives, true_negatives]]\n",
        "fig = px.imshow(z, x=x, y=y, color_continuous_scale='blues', aspect=\"auto\",  labels = {'x':'<b>Predicted Labels</b>', 'y': '<b>True Labels</b>'}, width=770,height=500)\n",
        "fig.update_traces(text=z_text, texttemplate=\"%{text}\")\n",
        "fig.update_xaxes(side=\"top\")\n",
        "pio.write_image(fig, 'con_mat_187.png',  scale=2)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision = true_positives/(true_positives + false_positives)\n",
        "recall = true_positives/(true_positives + false_negatives)\n",
        "f1_score = 2 * ((precision * recall)/(precision + recall))\n",
        "accuracy = (true_positives + true_negatives)/(true_positives + true_negatives + false_positives + false_negatives)\n",
        "\n",
        "precision, recall, f1_score, accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkZhsKHfpyrv",
        "outputId": "865dcea6-91d6-4aee-900b-bf4f98ce6c52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.85, 0.918918918918919, 0.8831168831168831, 0.9999305523403861)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWufhLB6k6mX",
        "outputId": "139999c8-812a-4773-e97f-7cc39a6d04f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "model.save(MODEL_TF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlLwqaaDTq_R"
      },
      "source": [
        "**Tensorflow Lite**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CSd9P5UVrSh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0e61912-1745-414c-bb79-76a74a9b4d17"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23548"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "# MODEL CONVERSION TFLITE\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_TF)\n",
        "model_no_quant_tflite = converter.convert()\n",
        "\n",
        "open(MODEL_NO_QUANT_TFLITE, \"wb\").write(model_no_quant_tflite)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ce4V34G-IQgG"
      },
      "outputs": [],
      "source": [
        "tf.lite.experimental.Analyzer.analyze(model_content=model_no_quant_tflite)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6iKX7vKWZlr"
      },
      "source": [
        "**Tensorflow Lite Quantized**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxJM9P_2eMlc"
      },
      "outputs": [],
      "source": [
        "testX32 =testX.astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pS-EWEm5dByt"
      },
      "outputs": [],
      "source": [
        "testX32[:300].reshape(1,-1)\n",
        "testX32\n",
        "mcu_test= pd.DataFrame(testX32.reshape(-1,1))\n",
        "mcu_test= mcu_test[:300]\n",
        "mcu_test.to_csv('mcu_test_187.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rq9TXYmQeOVm"
      },
      "outputs": [],
      "source": [
        "def representative_dataset_gen(num_samples=50000):\n",
        "  for data in testX32[:num_samples]:\n",
        "    yield [data.reshape(1,1,1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0zxfBWnYBRg"
      },
      "outputs": [],
      "source": [
        "#TENSORFLOW LITE QUANTIZED\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_TF)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_dataset_gen\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8  # or tf.uint8\n",
        "converter.inference_output_type = tf.int8  # or tf.uint8\n",
        "tflite_quant_model = converter.convert()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_znLwQpg6oN"
      },
      "outputs": [],
      "source": [
        "open(MODEL_TFLITE, \"wb\").write(tflite_quant_model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.lite.experimental.Analyzer.analyze(model_content=tflite_quant_model)"
      ],
      "metadata": {
        "id": "lJncsNqlijY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.tensorflow.org/lite/performance/post_training_integer_quant#convert_using_integer-only_quantization\n",
        "TEST_CASES=129593\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_quant_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()[0]\n",
        "output_details = interpreter.get_output_details()[0]\n",
        "\n",
        "# predictions = np.zeros((500,), dtype=int)\n",
        "# prediction = np.array([])\n",
        "prediction= []\n",
        "for i in range(TEST_CASES):\n",
        "  if input_details['dtype'] == np.int8:\n",
        "    input_scale, input_zero_point = input_details[\"quantization\"]\n",
        "    output_scale, output_zero_point = output_details[\"quantization\"]\n",
        "    test_int8 = testX / input_scale + input_zero_point\n",
        "    test_int8= test_int8.astype(np.int8)\n",
        "\n",
        "  interpreter.set_tensor(input_details[\"index\"], test_int8[i:i+1, :, :])\n",
        "  interpreter.invoke()\n",
        "  output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
        "\n",
        "  y= (output.astype(float) - output_zero_point) * output_scale\n",
        "\n",
        "  prediction.append(y)\n",
        "\n",
        "\n",
        "   "
      ],
      "metadata": {
        "id": "z-qy4SMdr77C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = np.array(prediction)"
      ],
      "metadata": {
        "id": "T3GU__zq_BOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tflite_predictions = pd.DataFrame(predictions.reshape(-1,1))\n",
        "tflite_predictions.columns = ['y_value']"
      ],
      "metadata": {
        "id": "lkzIMH5uurdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mean Squared Error \n",
        "testPre_Inv=scaler.inverse_transform(testPredict.reshape(1, -1))\n",
        "testPreMCU_Inv= scaler.inverse_transform(predictions.reshape(1, -1))\n",
        "testX_Inv=scaler.inverse_transform(testX.reshape(1, -1))\n",
        "testY_Inv= scaler.inverse_transform(testY.reshape(1, -1))\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "mse_original= mean_squared_error(testPre_Inv, testY_Inv, squared=False)\n",
        "mse_mcu= mean_squared_error(testPreMCU_Inv, testY_Inv, squared=False)\n",
        "# mse2 = mean_squared_error(np_arr.reshape(1,-1), testY.reshape(1,-1))\n",
        "print(\"Tensorflow MSE is :\" , mse_original , \"\\n\" + \"Tensorflow Lite MSE is: \", mse_mcu)"
      ],
      "metadata": {
        "id": "gcCre4lKGJfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2lOe0WPqinA"
      },
      "source": [
        "**C CODE File Conversion**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyY6oCQ4YG4h"
      },
      "outputs": [],
      "source": [
        "# Install xxd if it is not available\n",
        "!apt-get update && apt-get -qq install xxd\n",
        "# Convert to a C source file, i.e, a TensorFlow Lite for Microcontrollers model\n",
        "!xxd -i {MODEL_TFLITE} > {MODEL_TFLITE_MICRO}\n",
        "# Update variable names\n",
        "REPLACE_TEXT = MODEL_TFLITE.replace('/', '_').replace('.', '_')\n",
        "!sed -i 's/'{REPLACE_TEXT}'/g_model/g' {MODEL_TFLITE_MICRO}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bFwSIxwcITE"
      },
      "outputs": [],
      "source": [
        "!cat {MODEL_TFLITE_MICRO}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vqq9Vo0QrKW"
      },
      "source": [
        "**COMPARE MODEL SIZE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Q98s1-KQdG4"
      },
      "outputs": [],
      "source": [
        "# Calculate size\n",
        "size_tf = os.path.getsize('/content/models/model/saved_model.pb')/1024\n",
        "size_no_quant_tflite = os.path.getsize(MODEL_NO_QUANT_TFLITE)/1024\n",
        "size_tflite = os.path.getsize(MODEL_TFLITE)/1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KktqdTv8Qgr0"
      },
      "outputs": [],
      "source": [
        "# Compare size\n",
        "model_size=pd.DataFrame.from_records(\n",
        "    [[\"TensorFlow\", size_tf, \"\"],\n",
        "     [\"TensorFlow Lite\", size_no_quant_tflite, f\"(reduced by {size_tf - size_no_quant_tflite} bytes)\"],\n",
        "     [\"TensorFlow Lite Quantized\", size_tflite, f\"(reduced by {size_no_quant_tflite - size_tflite} bytes)\"]],\n",
        "     columns = [\"Model\", \"Size\", \"Size_Comparison\"], index=\"Model\")\n",
        "model_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sx7xLHy1EOCA"
      },
      "outputs": [],
      "source": [
        "model_size.to_csv('/path/model_size_187.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ho-mlCvnEFzq"
      },
      "outputs": [],
      "source": [
        "fig = px.bar(model_size, x=model_size.index, y='Size', text_auto=True, width=750,height=500, labels={'Size': 'Size (kB)', 'Model': 'Models'})\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWpBNHTdy-Tn"
      },
      "outputs": [],
      "source": [
        "size_187= pd.read_csv('/path/model_size_187.csv')\n",
        "size_189= pd.read_csv('/path/model_size_189.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKL1OZvo0DcX"
      },
      "outputs": [],
      "source": [
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = make_subplots( rows=1, cols=2,horizontal_spacing=0.11, subplot_titles=(\"(a)\", \"(b)\" ))\n",
        "\n",
        "fig.add_trace(go.Bar(y=size_187['Size'], x=size_187['Model']),\n",
        "              row=1, col=1)\n",
        "\n",
        "fig.add_trace(go.Bar(y=size_189['Size'], x=size_189['Model']),\n",
        "              row=1, col=2)\n",
        "\n",
        "fig.update_layout(height=500, width=1200)\n",
        "\n",
        "fig.update_layout(\n",
        "    plot_bgcolor='white'\n",
        ")\n",
        "fig.update_xaxes(\n",
        "    mirror=True,\n",
        "    ticks='outside',\n",
        "    showline=True,\n",
        "    linecolor='lightgrey',\n",
        "    gridcolor='lightgrey',\n",
        "    tickmode = 'array'\n",
        ")\n",
        "fig.update_yaxes(\n",
        "    title_text=\"Size (kB)\",\n",
        "    mirror=True,\n",
        "    ticks='outside',\n",
        "    showline=True,\n",
        "    linecolor='lightgrey',\n",
        "    gridcolor='lightgrey'\n",
        ")\n",
        "# fig.add_annotation(\n",
        "#     text='(a), ', \n",
        "#     xref='paper', \n",
        "#     x=0.1, \n",
        "#     yref='paper', \n",
        "#     y=0.48, \n",
        "#     showarrow=False\n",
        "# )\n",
        "# rotate all the subtitles of 90 degrees\n",
        "for annotation in fig['layout']['annotations']: \n",
        "        annotation['y']=-0.17\n",
        "        annotation['font']= dict(size=13)\n",
        "fig.update_layout(showlegend=False)\n",
        "fig.update_traces(width=0.3)\n",
        "\n",
        "fig.show()\n",
        "\n",
        "pio.write_image(fig, 'Size_Comparison.png',  scale=1.5)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1XdmfhLdvo38nqBAUc-5jEgPT9sYaqbWN",
      "authorship_tag": "ABX9TyOuYNo/HfoICAljTC0d5lBI"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}